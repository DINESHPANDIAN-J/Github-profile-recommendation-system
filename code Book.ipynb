{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "from github import Github\n",
    "\n",
    "# Replace 'YOUR_TOKEN' with your GitHub token\n",
    "g = Github(\"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\")\n",
    "\n",
    "def get_user_details(username):\n",
    "    user = g.get_user(username)\n",
    "\n",
    "    # Get languages\n",
    "    languages = {}\n",
    "    for repo in user.get_repos():\n",
    "        try:\n",
    "            for language, bytes in repo.get_languages().items():\n",
    "                languages[language] = languages.get(language, 0) + bytes\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching languages for repository {repo.full_name}: {e}\")\n",
    "\n",
    "    # Get starred repositories\n",
    "    starred_repositories = []\n",
    "    try:\n",
    "        starred_repositories = [repo.html_url for repo in user.get_starred()]\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching starred repositories for user {username}: {e}\")\n",
    "\n",
    "    # Get subscriptions\n",
    "    subscriptions = []\n",
    "    try:\n",
    "        subscriptions = [repo.html_url for repo in user.get_subscriptions()]\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching subscriptions for user {username}: {e}\")\n",
    "\n",
    "    # Get organizations\n",
    "    organizations = []\n",
    "    try:\n",
    "        organizations = [org.login for org in user.get_orgs()]\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching organizations for user {username}: {e}\")\n",
    "\n",
    "    # Get followers list\n",
    "    followers_list = []\n",
    "    try:\n",
    "        followers_list = [follower.login for follower in user.get_followers()]\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching followers for user {username}: {e}\")\n",
    "\n",
    "    # Get following list\n",
    "    following_list = []\n",
    "    try:\n",
    "        following_list = [following.login for following in user.get_following()]\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching following for user {username}: {e}\")\n",
    "\n",
    "    user_details = {\n",
    "        'login': user.login,\n",
    "        'name': user.name,\n",
    "        'bio': user.bio,\n",
    "        'public_repos': user.public_repos,\n",
    "        'followers_count': user.followers,\n",
    "        'following_count': user.following,\n",
    "        'created_at': user.created_at,\n",
    "        'updated_at': user.updated_at,\n",
    "        'avatar_url': user.avatar_url,\n",
    "        'profile_url': user.html_url,\n",
    "        'total_commits': 0,  # You may need to fetch this separately\n",
    "        'languages': languages,\n",
    "        'starred_repositories': starred_repositories,\n",
    "        'subscriptions': subscriptions,\n",
    "        'organizations': organizations,\n",
    "        'followers_list': followers_list,\n",
    "        'following_list': following_list\n",
    "    }\n",
    "    return user_details\n",
    "\n",
    "def write_to_csv(user_details, filename):\n",
    "    header = list(user_details.keys())\n",
    "    try:\n",
    "        with open(filename, 'a', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.DictWriter(file, fieldnames=header)\n",
    "            if file.tell() == 0:\n",
    "                writer.writeheader()\n",
    "            writer.writerow(user_details)\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing to CSV: {e}\")\n",
    "\n",
    "def get_organization_members_details(organization_name, count=10, filename='user_details.csv'):\n",
    "    organization = g.get_organization(organization_name)\n",
    "    members = organization.get_members()\n",
    "    try:\n",
    "        for member in members[:count]:  # Fetch details for the first 'count' members\n",
    "            try:\n",
    "                user_details = get_user_details(member.login)\n",
    "                write_to_csv(user_details, filename)\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching details for member {member.login}: {e}\")\n",
    "            # Add a small delay to avoid rate limiting\n",
    "            time.sleep(1)  # You can adjust this delay as needed\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching organization members: {e}\")\n",
    "\n",
    "# Example usage:\n",
    "organization_name = 'wordpress'  # Replace with your organization name\n",
    "get_organization_members_details(organization_name, count=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def combine_csv_files(folder_path, combined_filename):\n",
    "    # List all CSV files in the folder\n",
    "    csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "    \n",
    "    # Initialize an empty DataFrame to store combined data\n",
    "    combined_data = pd.DataFrame()\n",
    "\n",
    "    # Loop through each CSV file and concatenate data\n",
    "    for file in csv_files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        data = pd.read_csv(file_path)\n",
    "        combined_data = pd.concat([combined_data, data], ignore_index=True)\n",
    "\n",
    "    # Write combined data to a single CSV file\n",
    "    combined_data.to_csv(combined_filename, index=False)\n",
    "    print(f\"Combined CSV file saved as {combined_filename}\")\n",
    "\n",
    "\n",
    "folder_path = \"data\"  \n",
    "combined_filename = \"combined_data.csv\"   # Name of the combined CSV file\n",
    "combine_csv_files(folder_path, combined_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Store in mongodb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Define your MongoDB connection parameters\n",
    "mongodb_connection_string = \"mongodb+srv://Dinesh_pandian_j:14114@cluster0.kxes2.mongodb.net/\"\n",
    "collection_name = \"github_users\"  # Name of the collection to store GitHub users data\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(mongodb_connection_string)\n",
    "db = client.get_database(\"GRS\")  \n",
    "collection = db[collection_name]\n",
    "\n",
    "# Define a function to insert GitHub user data into MongoDB\n",
    "def insert_github_user(user_data):\n",
    "    collection.insert_one(user_data)\n",
    "\n",
    "# Path to your CSV file\n",
    "csv_file_path = \"your_csv_file.csv\"\n",
    "\n",
    "# Open the CSV file and read its contents\n",
    "with open(csv_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    # Iterate over each row in the CSV file\n",
    "    for row in reader:\n",
    "        # Insert each row as a document into your MongoDB collection\n",
    "        insert_github_user(row)\n",
    "\n",
    "print(\"CSV data has been successfully imported into MongoDB.\")\n",
    "\n",
    "print(f\"Database '{db.name}' and collection '{collection.name}' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GRS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0 (tags/v3.12.0:0fb18b0, Oct  2 2023, 13:03:39) [MSC v.1935 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "be4b5d0aeb88e8c91b778ec27f086aba2deedcaedc03bc0421edc1e74a586d1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
